# Key-value база данных

## Описание задачи

Написать key-value базу данных, соответствующую следующим условиям:
1) Принимает входящие сообщения по RabbitMQ из очереди config.INCOME_QUEUE. Отправляет ответ в очередь config.OUTCOME_QUEUE. Формат сообщений разработать и задокументировать самостоятельно.
2) Поддерживает операции чтения, вставки, удаления.
3) Обеспечивает персистентность данных через механизмы snapshot + log.
Тестовое задание должно запускаться через docker. Должен быть написан docker-compose файл, обеспечивающий персистентность базы.

## Конфигурация
Сервис конфигурируется следующими переменными окружения

| Variable name  | Required | Default Value | Description                                      |
| -------------- | -------- | ------------- | ------------------------------------------------ |
| AMQP_URL       | true     | -             | URL AMQP-хоста                                   |
| INCOME_QUEUE   | true     | -             | Имя очереди для входящих сообщений               |
| OUTCOME_QUEUE  | true     | -             | Имя очереди для исходящих сообщений              |
| DB_PATH        | true     | -             | Путь к директории с файлами базы                 |
| LOG_LEVEL      | false    | info          | Уровень логгирования (error, info, debug, trace) |

## Запуск
### В контейнере

Перед запуском необходимо проверить конфигурацию в файлах `Dockerfile` и `docker-compose.yaml`.
Обратите внимание на название директории, в которую будет смонтирована внешняя папка для файлов базы (см. `volumes.source` в `docker-compose.yaml`).
По-умолчанию это `./storage`.

Для запуска выполнить команду
```bash
$ docker-compose up --build
```

### На локальном компьютере

Настроить конфигурацию в файле `./config/config.js` либо задав переменные окружения.

Для запуска выполнить команду
```bash
$ npm run start
```

## Подробности реализации

При старте сервис парсит все файлы из заданной директории и загружает их в память. Проверка типа и содержимого файлов не проводится (см. ниже).
Дамп сбрасывается на диск каждые 10 секунд при условии, что данные в памяти были изменены, либо при получении сигналов `SIGINT` или `SIGTERM`.

Входящие сообщения вычитываются из очереди `INCOME_QUEUE`, ответ записывается в очередь `OUTCOME_QUEUE`.

В качестве ключей допускается использование только строк или чисел. Не допускается использование символа `:` в имени ключа (будет выброшена ошибка).

### Формат сообщений
#### Входящие сообщения
Обязательные поля - `id` и `method`.
Список публичных методов, которые могут быть вызваны, определяются в файле `service.js` в переменной `dbPublicMethods`

Получение записи
```javascript
{
    id: 100,
    method: 'get',
    params: {
        key: '112233',
    },
}
```

Добавление записи (если такого ключа не существует) или обновление существующей записи
```javascript
{
    id: 100,
    method: 'set',
    params: {
        key: '123',
        value: 'anything',
    },
}
```

Получение количества записей
```javascript
{
    id: 100,
    method: 'count',
}
```

Удаление записи - если записи не существует, ошибка не будет выброшена
```javascript
{
    id: 100,
    method: 'delete',
    params: {
        key: '112233',
    },
}
```

#### Исходящие сообщения
Исходящие сообщения содержат поле `request` (копия запроса), `response` если запрос успешно обработан или `error`, если во время обработки произошла ошибка

```javascript
 {
   request: {
     id: 9,
     method: 'delete',
     params: { key: 10 }
   },
   response: true
 }
```

## Недостатки реализации и способы их решения
#### Формат хранения данных
Информация хранится в текстовом виде. Это накладывает ограничения на кодировки (только utf-8), а так же на формат самих данных (только строки).

Решением может быть использование бинарного формата для ключей и их значений. Тип данных может быть указан специальными символами либо последовательностью байт.
Например, первые несколько байт могут определять формат ключа и значения, следующие несколько байт - длину значения, дальше - само значение, и в конце несколько байт - контрольная сумма для проверки целостности данных.

#### Целостность данных
Никаких проверок на целостность в данный момент не производится. Возможное решение описано выше.

#### Структура файлов хранилища
Все данные пишутся в один файл. При определенных размерах это непременно приведет к полному исчерпанию памяти и вылету сервиса.

Решение - дробить данный на куски определенных размеров и писать их в отдельные файлы.

#### Скорость доступа к файлам, индексирование
При использовании бинарного формата довольно просто реализовать механизм индексирования - при запуске сервис может открывать все файлы,
получать их дескрипторы, и сохранять в память структуру в виде массива, каждый элемент которого представляет следующее:

```javascript
[
     {
        fd: 123, // дескриптор файла
        data: [
            { key: 1, offset: 0x100 }, // key - имя ключа, offset - смещение внутри файла
            { key: 2, offset: 0x1000 },
            ...
            { key: N, offset: 0x100000 },
        ],
    },
];
```

Это позволит выгружать не все данные в память, а только ключи и смещения,
и при этом иметь информацию в каком фале и по какому смещению находится значение того или иного ключа.

При удалении записи, которая находится в файле, достаточно заменить контрольную сумму нулями, пометив таким образом, что запись была удалена.
В дальнейшем, по таймеру, можно чистить файлы физически, удаляя все помеченные записи и перезаписывая файлы с данными.

При модификации записи делать подобным образом - существующую информацию в файле помечать как удаленную,
новую информацию писать в конец существующего, либо же создавать новый файл. 

#### Многопоточность
Многопоточность можно реализовать с использованием стандартного модуля `cluster`, либо на уровне контейнеров, где будет один основной процесс,
который распределяет нагрузку, блокирует доступ к записям и данным в хранилище (для исключения race-conditions), а воркеры выполняют остальную рутину.

Каждый воркер, например, может работать лишь с определенными файлами из хранилища.

Протокол обмена между мастером и вокрерами может быть любой - IPC в случае использования `cluster`, TCP, Http, etc.

Пример выполненного тестового задания, в котором реализована многопоточноть - https://github.com/mekh/vilmate-rdf-meta-extractor
В данном примере нагрузка распределяется с использованием алгоритма Round-robin.
